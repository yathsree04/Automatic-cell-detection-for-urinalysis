{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic white blood cell detection in urine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Known characterstics of substituents in urine samples:\n",
    "- WBC:-\n",
    "Small in size, Circular/ellipsoid, Grainy texture\n",
    "- RBC:- \n",
    "Circular ,Smooth texture ,Higher Luminance\n",
    "- Dust particles:-\n",
    "Sharp edges,Irregular shape,Larger than WBC and RBC\n",
    "- Epithelial cells:-\n",
    "Largest in size, Ellipsoid , Horizontally grained texture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------- Loading Images in list ----------------#\n",
    "import os\n",
    "import glob\n",
    "img_dir = r'C:\\Users\\Lenovo\\Desktop\\Vinti Agarwal\\images'\n",
    "data_path = os.path.join(img_dir,'*g')\n",
    "files = glob.glob(data_path)\n",
    "data = []\n",
    "for f1 in files:\n",
    "    img = cv.imread(f1,0)\n",
    "    data.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing methodology referenced in work by Jennifer C. et. al \n",
    " ##### Methodology: -\n",
    "- Gaussian Filtering\n",
    "- Gradient(Magnitude) transformation \n",
    "- Canny edge detection \n",
    "- Hough transform for circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_circles = []\n",
    "for i in range(0,len(data)):\n",
    "        temp = data[i].copy()\n",
    "        blur = cv.GaussianBlur(temp, (5,5) , 0)                #Gaussian blur filter\n",
    "        kernel = np.ones((3,3), np.uint8)                      #Defining kernel for Morphing  \n",
    "        mg = cv.morphologyEx(blur, cv.MORPH_GRADIENT, kernel)  # Morphological Transformation\n",
    "    #Canny edge detection is implemented along with Hough Transformation in the OpenCv implementation  \n",
    "        circles = cv.HoughCircles(mg,cv.HOUGH_GRADIENT, 1, 30, param1 = 20 , param2 = 28, minRadius=4, maxRadius= 25)\n",
    "        detected_circles = np.uint16(np.around(circles))\n",
    "        num_circles.append(detected_circles.shape[1])          # Storing number of circles detected in a list\n",
    "        for (x,y,r) in detected_circles[0, :]:\n",
    "            cv.circle(temp , (x,y), r , (0,0,255), 3 )\n",
    "        plt.subplot(3, 2, i+1), plt.imshow(temp, 'gray')\n",
    "        plt.xticks([]),plt.yticks([])\n",
    "        plt.title('Number of circles : {}'.format(num_circles[i]))\n",
    "\n",
    "plt.show()\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was seen that the algorithm misclassified a lot of circles on Sharp dust particles and left out many out of focus WBC, this might be due to the default implemented Sobel High pass filter in OpenCV's HoughCircles() function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primary Approach : Hough Circle Transform with Median Filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using Hough Transform with median filtering \n",
    "num_circles = []\n",
    "for i in range(0,len(data)):\n",
    "        temp = data[i].copy()\n",
    "    #Various High pass filters tried to detect grainy structure of WBC, but they make the image too noisy\n",
    "        \n",
    "        #temp_2 = cv.Laplacian(temp,cv.CV_8UC1,ksize=3)      \n",
    "        #sobelx = cv.Sobel(temp,cv.CV_8UC1,1,0,ksize=5)\n",
    "        #sobely = cv.Sobel(temp,cv.CV_8UC1,1,0,ksize=5)\n",
    "        #scharr = cv.Scharr(blur,cv.CV_8UC1,1,0)\n",
    "        #canny = cv.Canny(blur, 50, 250)\n",
    "       \n",
    "    # Median Filtering for smoothening and noise removal \n",
    "        blur = cv.medianBlur(temp, 5)                     \n",
    "        #kernal = np.ones((1,1), np.uint8)\n",
    "        #mg = cv.morphologyEx(scharr, cv.MORPH_GRADIENT, kernal)\n",
    "        circles = cv.HoughCircles(blur,cv.HOUGH_GRADIENT, 1, 30, param1 = 20 , param2 = 28, minRadius=4, maxRadius= 25) #Parameters adjusted using trackbar tuning \n",
    "        detected_circles = np.uint16(np.around(circles))\n",
    "        num_circles.append(detected_circles.shape[1])   \n",
    "        for (x,y,r) in detected_circles[0, :]:\n",
    "            cv.circle(temp , (x,y), r , (0,255,0), 3 )\n",
    "            #cv.circle(temp, (x,y), 2 , (255,0,0), 3)   # plot circle center\n",
    "        plt.subplot(3, 2, i+1), plt.imshow(temp, 'gray')\n",
    "        plt.xticks([]),plt.yticks([])\n",
    "        plt.title('Number of circles : {}'.format(num_circles[i]))\n",
    "\n",
    "plt.show()\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hough transform without filtering\n",
    "num_circles = []\n",
    "for i in range(0,len(data)):\n",
    "        temp = data[i].copy()\n",
    "        circles = cv.HoughCircles(temp,cv.HOUGH_GRADIENT, 1, 30, param1 = 20 , param2 = 28, minRadius=4, maxRadius= 25)\n",
    "        detected_circles = np.uint16(np.around(circles))\n",
    "        num_circles.append(detected_circles.shape[1])\n",
    "        for (x,y,r) in detected_circles[0, :]:\n",
    "            cv.circle(temp , (x,y), r , (0,255,0), 3 )\n",
    "            cv.circle(temp, (x,y), 2 , (255,0,0), 3)\n",
    "        plt.subplot(3, 2, i+1), plt.imshow(temp, 'Image')\n",
    "        plt.xticks([]),plt.yticks([])\n",
    "        plt.title('Number of circles : {}'.format(num_circles[i]))\n",
    "\n",
    "plt.show()\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm with median filtering does a better job in identifying WBC from dust particles and RBC, in all images but the last compared to the algorithm without median filtering. This might be due to the image being out of focus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dealing with Blurry images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance of 0 image is : 33.73461477206078\n",
      "Variance of 1 image is : 34.571261698403774\n",
      "Variance of 2 image is : 30.984391110473204\n",
      "Variance of 3 image is : 31.935109559959823\n",
      "Variance of 4 image is : 36.075897952228125\n",
      "Variance of 5 image is : 55.33378541666232\n"
     ]
    }
   ],
   "source": [
    "#Detecting blurry images using variance of Laplacian operator\n",
    "def variance_of_laplacian(image):\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "for i in range(0,len(data)):\n",
    "    print(\"Variance of {} image is : {}\".format(i,variance_of_laplacian(data[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, images with lower variance of Laplacian operator tends to be blurry. However, the opposite is true in our case, because all hte images are quite similar. Even when focussed, these images have low variance because of homegenity. A blur caused by camera reduces this homegenity and increases the variance of the image. It can thus be concluded that, images with higher variance in this dataset are blurry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Removing filtering for image 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv.imread(r'C:\\Users\\Lenovo\\Desktop\\Vinti Agarwal\\images\\0047.jpg',0)\n",
    "temp= image.copy()\n",
    "blur = cv.medianBlur(temp, 1)\n",
    "circles = cv.HoughCircles(temp,cv.HOUGH_GRADIENT, 1, 30, param1 = 20 , param2 = 28, minRadius=4, maxRadius= 25)\n",
    "detected_circles = np.uint16(np.around(circles))\n",
    "for (x,y,r) in detected_circles[0, :]:\n",
    "        cv.circle(temp , (x,y), r , (0,255,0), 3 )\n",
    "        #cv.circle(temp, (x,y), 2 , (255,0,0), 3)\n",
    "cv.imshow(\"temp\",temp)\n",
    "plt.title('Number of circles : {}'.format(detected_circles.shape[1]))\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternate approaches  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding contours in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using contours ->>> Failed\n",
    "image = cv.imread(r'C:\\Users\\Lenovo\\Desktop\\Vinti Agarwal\\images\\0047.jpg',0)\n",
    "temp = image.copy()\n",
    "_ , thresh = cv.threshold(temp, 25, 255, cv.THRESH_BINARY)\n",
    "contours, _ = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n",
    "for contour in contours:\n",
    "    approx = cv.approxPolyDP(contour, 0.01* cv.arcLength(contour, True), True)\n",
    "    x = approx.ravel()[0]\n",
    "    y = approx.ravel()[1] - 5\n",
    "    if len(approx) >= 4:\n",
    "        cv.drawContours(temp, [approx], 0, (0, 0, 0), 5)\n",
    "cv.imshow('image', temp)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, this algorithm can't be used, as it's not able to find any contours in the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template Matching "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FInding multiple templates of WBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding template coordinates for crop\n",
    "image = cv.imread(r'C:\\Users\\Lenovo\\Desktop\\Vinti Agarwal\\images\\0005.jpg',0) # Change path for different templates \n",
    "def click_event(event, x, y, flags, param):                 #Defining click events to find coordinates in the image\n",
    "    if event == cv.EVENT_LBUTTONDOWN:\n",
    "        print(x,', ' ,y)\n",
    "        font = cv.FONT_HERSHEY_SIMPLEX\n",
    "        strXY = str(x) + ', '+ str(y)\n",
    "        cv.putText(temp, strXY, (x, y), font, .5, (255, 255, 0), 2)\n",
    "        cv.imshow('image', temp)\n",
    "    if event == cv.EVENT_RBUTTONDOWN:\n",
    "        blue = temp[y, x, 0]\n",
    "        green = temp[y, x, 1]\n",
    "        red = temp[y, x, 2]\n",
    "        font = cv.FONT_HERSHEY_SIMPLEX\n",
    "        strBGR = str(blue) + ', '+ str(green)+ ', '+ str(red)\n",
    "        cv.putText(temp, strBGR, (x, y), font, .5, (0, 255, 255), 2)\n",
    "        cv.imshow('image', temp)\n",
    "        \n",
    "temp = image.copy()\n",
    "cv.imshow('image', temp)\n",
    "cv.setMouseCallback('image', click_event)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cropping first template\n",
    "crop_img = temp[308:365, 275:339]\n",
    "cv.imshow(\"cropped\", crop_img)\n",
    "cv.imwrite('template.jpg', crop_img) # Saving template image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv.imread(r'C:\\Users\\Lenovo\\Desktop\\Vinti Agarwal\\images\\0047.jpg',0)\n",
    "#cropping Second template (from image 0047)\n",
    "crop_img_2 = temp[154:188, 413:445]\n",
    "cv.imshow(\"cropped\", crop_img_2)\n",
    "cv.imwrite('template_2.jpg', crop_img_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Matching templates to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use template matching with multiple templates\n",
    "template_1 = cv.imread(r'C:\\Users\\Lenovo\\Desktop\\Vinti Agarwal\\template.jpg', 0)\n",
    "template_2 = cv.imread(r'C:\\Users\\Lenovo\\Desktop\\Vinti Agarwal\\template_2.jpg', 0)\n",
    "w, h = template_1.shape[::-1]\n",
    "for i in range(0,len(data)):\n",
    "    temp = data[i].copy()\n",
    "    res = cv.matchTemplate(temp, template_1, cv.TM_CCORR_NORMED )\n",
    "    res_1 = cv.matchTemplate(temp, template_2, cv.TM_CCORR_NORMED )\n",
    "    threshold_1 = 0.987;\n",
    "    threshold_2 = 0.986 ;\n",
    "    loc = np.where(res >= threshold_1)\n",
    "    loc_1 = np.where(res_1 >= threshold_2)\n",
    "    for pt in zip(*loc[::-1]):\n",
    "        cv.rectangle(temp, pt, (pt[0] + w, pt[1] + h), (0, 0, 255), 2)\n",
    "    for pt in zip(*loc_1[::-1]):\n",
    "        cv.rectangle(temp, pt, (pt[0] + w, pt[1] + h), (0, 0, 255), 2)\n",
    "    plt.subplot(3, 2, i+1) \n",
    "    plt.imshow(temp,'gray')\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, this is not a scalable approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimental : HSV segmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HSV\n",
    "# Finding paramters\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cv.namedWindow(\"Tracking\")\n",
    "cv.createTrackbar(\"LH\", \"Tracking\", 0, 255, nothing)\n",
    "cv.createTrackbar(\"LS\", \"Tracking\", 0, 255, nothing)\n",
    "cv.createTrackbar(\"LV\", \"Tracking\", 0, 255, nothing)\n",
    "cv.createTrackbar(\"UH\", \"Tracking\", 255, 255, nothing)\n",
    "cv.createTrackbar(\"US\", \"Tracking\", 255, 255, nothing)\n",
    "cv.createTrackbar(\"UV\", \"Tracking\", 255, 255, nothing)\n",
    "\n",
    "while True:\n",
    "    image = cv.imread(r'C:\\Users\\Lenovo\\Desktop\\Vinti Agarwal\\images\\0047.jpg')\n",
    "    frame= image.copy()\n",
    "\n",
    "    hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "\n",
    "    l_h = cv.getTrackbarPos(\"LH\", \"Tracking\")\n",
    "    l_s = cv.getTrackbarPos(\"LS\", \"Tracking\")\n",
    "    l_v = cv.getTrackbarPos(\"LV\", \"Tracking\")\n",
    "\n",
    "    u_h = cv.getTrackbarPos(\"UH\", \"Tracking\")\n",
    "    u_s = cv.getTrackbarPos(\"US\", \"Tracking\")\n",
    "    u_v = cv.getTrackbarPos(\"UV\", \"Tracking\")\n",
    "\n",
    "    l_b = np.array([l_h, l_s, l_v])\n",
    "    u_b = np.array([u_h, u_s, u_v])\n",
    "\n",
    "    mask = cv.inRange(hsv, l_b, u_b)\n",
    "\n",
    "    res = cv.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    cv.imshow(\"frame\", frame)\n",
    "    cv.imshow(\"mask\", mask)\n",
    "    cv.imshow(\"res\", res)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting parameters found in above step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv.imread(r'C:\\Users\\Lenovo\\Desktop\\Vinti Agarwal\\images\\0047.jpg')\n",
    "frame= image.copy()\n",
    "hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "l_b = np.array([0, 0, 128])\n",
    "u_b = np.array([255, 255, 255])\n",
    "mask = cv.inRange(hsv, l_b, u_b)\n",
    "res = cv.bitwise_and(frame, frame, mask=mask)\n",
    "# Morphological operations\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "erosion = cv.erode(mask,kernel,iterations =1)\n",
    "cv.imshow(\"mask\", mask)\n",
    "cv.imshow(\"res\", res)\n",
    "cv.imshow(\"erosion\", erosion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
